########################################### <14> ##############################################

 # url_14 = 'https://www.fs.usda.gov/news/releases'
 USER_AGENT = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
 chrome_options = Options()
 chrome_options.page_load_strategy = 'normal'  # 'none', 'eager', 'normal'
 chrome_options.add_argument('--headless')
 chrome_options.add_argument('--no-sandbox')
 chrome_options.add_argument('--disable-dev-shm-usage')
 chrome_options.add_argument('--disable-gpu')
 chrome_options.add_argument(f'user-agent={USER_AGENT}')
 service = Service()
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_14)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 10, 18).date()     #For Test

 try:
     news_items = soup.find_all('div', class_='margin-bottom-2 views-row')
     if not news_items:
         error_list.append({
             'Error Link': url_14,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_tag = item.find('time', class_='text-base-darker')
             date_str = date_tag.get_text(strip=True)
             article_date = date_util(date_str)

             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title_tag = item.find('span', class_='field-content featured-title')
                 title = title_tag.get_text(strip=True)

                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"https://www.fs.usda.gov{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 content_div = article_soup.find('div', class_='usa-prose full-width')
                 article_body = ' '.join(p.get_text() for p in content_div.find_all('p')) #if content_div else "No content available."

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_14,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_14,
         'Error': str(e)
     })





 ########################################### <41> ##############################################

 #url_41 = 'https://sos.ga.gov/news/division/31?page=0'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 # today = datetime(2023, 11, 7).date()     # For Test

 try:
     news_items = soup.select(".card__content")
     if not news_items:
         error_list.append({
             'Error Link': url_41,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one('.card__date').get_text(strip=True)
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('.heading__link').get_text(strip=True)
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"https://sos.ga.gov{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 paragraphs = article_soup.select("div.layout-2x__content p")
                 article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)
                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_41,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_41,
         'Error': str(e)
     })




 ########################################### <42> ##############################################

 #url_42 = 'https://gov.georgia.gov/press-releases'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 # today = datetime(2023, 11, 8).date()     # For Test

 try:
     news_items = soup.select(".news-teaser")
     if not news_items:
         error_list.append({
             'Error Link': url_42,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one('.global-teaser__description').get_text(strip=True)
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('.global-teaser__title').get_text(strip=True)
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"https://gov.georgia.gov{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 paragraphs = article_soup.select("main.content-page__main p")
                 article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)
                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_42,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_42,
         'Error': str(e)
     })




 ########################################### <44> ##############################################

 #url_44 = 'https://www.georgia.org/press-releases'   #실험 후 주석처리
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_44)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 10, 31).date()     #For Test

 try:
     news_items = soup.select("[class=info]")
     if not news_items:
         error_list.append({
             'Error Link': url_44,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one('.date').get_text(strip=True)
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")
             if article_date == today:
                 a_tag = item.find('a')
                 if not a_tag: error_message = Error_Message(error_message, "a_tag 못찾음")
                 all_text = a_tag.get_text(strip=True)
                 not_title = a_tag.find('span', class_='date').get_text(strip=True)
                 title = all_text.replace(not_title, '').strip('" ')
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"https://www.georgia.org{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 content_div = article_soup.find('div', class_="field field--name-field-main-content-body field--type-text-with-summary field--label-hidden field__item")
                 if not content_div: error_message = Error_Message(error_message, "content_div 못찾음")
                 article_body = content_div.get_text(separator='\n', strip=True)

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_44,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_44,
         'Error': str(e)
     })





 ########################################### <45> ##############################################

 #url_45 = 'https://www.gachamber.com/all-news/'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_45)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 # today = datetime(2023, 10, 6).date()     #For Test

 try:
     news_items = soup.select(".fl-post-feed-post")
     if not news_items:
         error_list.append({
             'Error Link': url_45,
             'Error': "None News"
         })
     else:
         for item in news_items:
             meta_tag = item.find('div', class_='fl-post-meta')
             parts = meta_tag.get_text(strip=True).split('·')
             date_str = parts[-1].strip()
             article_date = date_util(date_str)

             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('a').get_text(strip=True)
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = item.find('h2').find('a')['href']
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 parent_div = article_soup.find('div', class_="fl-module fl-module-fl-post-content fl-node-5cb515ec1b22a")
                 paragraphs = parent_div.select(".fl-module-content.fl-node-content p") #if parent_div else []
                 article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_45,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_45,
         'Error': str(e)
     })




 ########################################### <68> ##############################################

 #url_68 = 'https://ag.ny.gov/press-releases'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_68)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 11, 8).date()     #For Test

 try:
     news_items = soup.find_all('div', class_='views-row')
     if not news_items:
         error_list.append({
             'Error Link': url_68,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one(".field-content").get_text(strip=True)
             article_date = date_util(date_str)

             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('a').get_text(strip=True)

                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"https://ag.ny.gov{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 content_div = article_soup.find('div', class_="node-content tw-typography tw-container tw-mt-8")
                 article_body = ' '.join(p.get_text() for p in content_div.find_all('p')) #if content_div else "No content available."

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_68,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_68,
         'Error': str(e)
     })





 ########################################### <83> ##############################################

 #url_83 = "https://ncchamber.com/category/chamber-updates/"
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_83)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 today = datetime(2023, 11, 8).date()     #실험용 날짜

 try:
     news_items = soup.select(".entry-article")
     if not news_items:
         error_list.append({
             'Error Link': url_83,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one('time[datetime]').get_text(strip=True)
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('h2 a').get_text(strip=True)
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"{item.a['href']}"
                 if not article_link:  # 이 부분이 수정되었습니다. `article_link`가 아니라 `link`를 확인해야 합니다.
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 content = article_soup.select_one(".container-post")
                 paragraphs = content.find_all("p")
                 article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)
                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":  # 이 부분이 수정되었습니다. `str()` 대신 빈 문자열 `""`을 사용합니다.
                     error_list.append({
                         'Error Link': url_83,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_83,
         'Error': str(e)
     })




 ########################################### <88> ##############################################

 #url_88 = 'https://www.governor.virginia.gov/newsroom/news-releases/' 
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_88)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 11, 10).date()     #For Test


 try:
     news_items = soup.select(".col-md-12")
     if not news_items:
         error_list.append({
             'Error Link': url_88,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one(".date").text.strip().strip('"')
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one(".va-icon--arrow-ext").text
                 if not title:
                     error_message = Error_Message(error_message, "None Title")
                 article_link = f"https://www.governor.virginia.gov{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 article_body = None
                 tables = article_soup.select('table.x_layout.x_layout--1-column')
                 if tables:
                     article_body = ' '.join([table.get_text(strip=True) for table in tables])

                 if not article_body:
                     tables = article_soup.select('table.layout.layout--1-column')
                     if tables:
                         article_body = ' '.join([table.get_text(strip=True) for table in tables])

                 if not article_body:
                     divs = article_soup.select('div.col-lg-12.col-md-12.col-sm-12')
                     if divs:
                         paragraphs = [p.get_text(strip=True) for div in divs for p in div.select('p')]
                         article_body = ' '.join(paragraphs)

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_88,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_88,
         'Error': str(e)
     })



 ########################################### <91> ##############################################

 #url_91 = 'https://vachamber.com/category/press-releases/'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_91)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 11, 9).date()     #For Test

 try:
     news_items = soup.select(".archiveitem")
     if not news_items:
         error_list.append({
             'Error Link': url_91,
             'Error': "None News"
         })
     else:
         for item in news_items:
             date_str = item.select_one('.item_meta').get_text(strip=True)
             article_date = date_util(date_str)
             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('h4 a').get_text(strip=True)
                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"{item.a['href']}"
                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 content = article_soup.select_one(".content_wrapper_right")
                 if content:
                     news_contact = content.select_one(".newscontact")
                     if news_contact:
                         news_contact.decompose()
                     paragraphs = content.find_all("p")
                     for i, p in enumerate(paragraphs):
                         if "additional highlights" in p.get_text().lower():
                             paragraphs = paragraphs[:i]
                             break
                     article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_91,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_91,
         'Error': str(e)
     })





 ########################################### <93> ##############################################

 #url_93 = 'https://news.maryland.gov/mde/category/press-release/'
 wd = webdriver.Chrome(service=service, options=chrome_options)
 wd.get(url_93)
 time.sleep(5)
 html = wd.page_source
 soup = BeautifulSoup(html, 'html.parser')
 error_message = str()
 #today = datetime(2023, 11, 2).date()     #For Test

 try:
     news_items = soup.select(".type-post")
     if not news_items:
         error_list.append({
             'Error Link': url_93,
             'Error': "None News"
         })
     else:
         for item in news_items:
             li_tag = item.select_one('li')
             title_str = li_tag.select_one('a').text.strip()
             date_str = li_tag.text.replace(title_str, '').strip()
             article_date = date_util(date_str)

             if not article_date:
                 error_message = Error_Message(error_message, "None Date")

             if article_date == today:
                 title = item.select_one('a').get_text(strip=True)

                 if not title:
                     error_message = Error_Message(error_message, "None Title")

                 article_link = f"{item.a['href']}"

                 if not article_link:
                     error_message = Error_Message(error_message, "None Link")

                 wd.get(article_link)
                 article_html = wd.page_source
                 article_soup = BeautifulSoup(article_html, 'html.parser')

                 paragraphs = article_soup.select('.type-post p, .type-post ul')
                 article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)

                 if not article_body:
                     error_message = Error_Message(error_message, "None Contents")

                 if error_message != "":
                     error_list.append({
                         'Error Link': url_93,
                         'Error': error_message
                     })
                 else:
                     articles.append({
                         'Title': title,
                         'Link': article_link,
                         'Content(Raw)': article_body
                     })

 except Exception as e:
     error_list.append({
         'Error Link': url_93,
         'Error': str(e)
